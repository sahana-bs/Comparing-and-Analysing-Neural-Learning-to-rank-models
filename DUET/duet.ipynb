{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall keras\n",
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'h5py==2.10.0' --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matchzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INIT ###\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matchzoo as mz\n",
    "import json\n",
    "\n",
    "print('data loading ...')\n",
    "train_pack_raw = mz.datasets.wiki_qa.load_data('train', task='ranking')\n",
    "dev_pack_raw = mz.datasets.wiki_qa.load_data('dev', task='ranking', filtered=True)\n",
    "test_pack_raw = mz.datasets.wiki_qa.load_data('test', task='ranking', filtered=True)\n",
    "print('data loaded as `train_pack_raw` `dev_pack_raw` `test_pack_raw`')\n",
    "\n",
    "ranking_task = mz.tasks.Ranking(loss=mz.losses.RankHingeLoss())\n",
    "ranking_task.metrics = [\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=3),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=5),\n",
    "    mz.metrics.MeanAveragePrecision()\n",
    "]\n",
    "print(\"`ranking_task` initialized with metrics\", ranking_task.metrics)\n",
    "\n",
    "print(\"loading embedding ...\")\n",
    "glove_embedding = mz.datasets.embeddings.load_glove_embedding(dimension=300)\n",
    "print(\"embedding loaded as `glove_embedding`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_params_to_readme(model):\n",
    "    import tabulate\n",
    "    \n",
    "    with open('README.rst', 'a+') as f:\n",
    "        subtitle = model.params['model_class'].__name__\n",
    "        line = '#' * len(subtitle)\n",
    "        subtitle = subtitle + '\\n' + line + '\\n\\n'\n",
    "        f.write(subtitle)\n",
    "        \n",
    "        df = model.params.to_frame()[['Name', 'Value']]\n",
    "        table = tabulate.tabulate(df, tablefmt='rst', headers='keys') + '\\n\\n'\n",
    "        f.write(table)\n",
    "\n",
    "  ### END INIT ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = mz.preprocessors.BasicPreprocessor(fixed_length_left=10, fixed_length_right=100, remove_stop_words=True)\n",
    "train_pack_processed = preprocessor.fit_transform(train_pack_raw)\n",
    "valid_pack_processed = preprocessor.transform(dev_pack_raw)\n",
    "test_pack_processed = preprocessor.transform(test_pack_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mz.models.DUET()\n",
    "model.params.update(preprocessor.context)\n",
    "model.params['task'] = ranking_task\n",
    "model.params['embedding_output_dim'] = 300\n",
    "model.params['lm_filters'] = 32\n",
    "model.params['lm_hidden_sizes'] = [32]\n",
    "model.params['dm_filters'] = 32\n",
    "model.params['dm_kernel_size'] = 3\n",
    "model.params['dm_d_mpool'] = 4\n",
    "model.params['dm_hidden_sizes'] = [32]\n",
    "model.params['dropout_rate'] = 0.5\n",
    "optimizer = keras.optimizers.Adamax(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "model.params['optimizer'] = 'adagrad'\n",
    "model.guess_and_fill_missing_params()\n",
    "model.build()\n",
    "model.compile()\n",
    "model.backend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = glove_embedding.build_matrix(preprocessor.context['vocab_unit'].state['term_index'])\n",
    "model.load_embedding_matrix(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x, pred_y = test_pack_processed[:].unpack()\n",
    "evaluate = mz.callbacks.EvaluateAllMetrics(model, x=pred_x, y=pred_y, batch_size=len(pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = mz.DataGenerator(\n",
    "    train_pack_processed,\n",
    "    mode='pair',\n",
    "    num_dup=2,\n",
    "    num_neg=1,\n",
    "    batch_size=20\n",
    ")\n",
    "print('num batches:', len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, epochs=30, callbacks=[evaluate], workers=30, use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
