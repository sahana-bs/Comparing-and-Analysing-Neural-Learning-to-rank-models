{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Match_Pyramid.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qbo4tFnbdHz_",
        "outputId": "e2e833d6-46d2-469c-cc9b-ce0afd2dec38"
      },
      "source": [
        "'''\n",
        "keras: 2.3.1\n",
        "tensorflow: 2.1.0\n",
        "h5py: 2.10.0\n",
        "'''\n",
        "!pip install 'keras==2.3.1' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.3.1\n",
            "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting six>=1.9.0\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyyaml\n",
            "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Collecting numpy>=1.9.1\n",
            "  Using cached numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting scipy>=0.14\n",
            "  Using cached scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting cached-property\n",
            "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: numpy, cached-property, six, h5py, scipy, pyyaml, keras-preprocessing, keras-applications, keras\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "  Attempting uninstall: cached-property\n",
            "    Found existing installation: cached-property 1.5.2\n",
            "    Uninstalling cached-property-1.5.2:\n",
            "      Successfully uninstalled cached-property-1.5.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: keras-preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Attempting uninstall: keras-applications\n",
            "    Found existing installation: Keras-Applications 1.0.8\n",
            "    Uninstalling Keras-Applications-1.0.8:\n",
            "      Successfully uninstalled Keras-Applications-1.0.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "tensorflow 2.1.0 requires scipy==1.4.1; python_version >= \"3\", but you have scipy 1.7.3 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cached-property-1.5.2 h5py-3.6.0 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 numpy-1.21.4 pyyaml-6.0 scipy-1.7.3 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0R8l1OKzdH4V",
        "outputId": "b615ccfc-6baa-4cc7-b479-70be4e937636"
      },
      "source": [
        "!pip install 'tensorflow==2.1.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "  Using cached tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Using cached wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Using cached numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Using cached gast-0.2.2-py3-none-any.whl\n",
            "Collecting absl-py>=0.7.0\n",
            "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "Collecting six>=1.12.0\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting google-pasta>=0.1.6\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting wheel>=0.26\n",
            "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting scipy==1.4.1\n",
            "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting keras-preprocessing>=1.1.0\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Using cached grpcio-1.42.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "Collecting protobuf>=3.8.0\n",
            "  Using cached protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting setuptools>=41.0.0\n",
            "  Using cached setuptools-59.4.0-py3-none-any.whl (952 kB)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Using cached importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Using cached typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Using cached charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "Collecting cached-property\n",
            "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, numpy, importlib-metadata, google-auth, cached-property, wheel, werkzeug, protobuf, markdown, h5py, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.7\n",
            "    Uninstalling urllib3-1.26.7:\n",
            "      Successfully uninstalled urllib3-1.26.7\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.4.8\n",
            "    Uninstalling pyasn1-0.4.8:\n",
            "      Successfully uninstalled pyasn1-0.4.8\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.3\n",
            "    Uninstalling idna-3.3:\n",
            "      Successfully uninstalled idna-3.3\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.8\n",
            "    Uninstalling charset-normalizer-2.0.8:\n",
            "      Successfully uninstalled charset-normalizer-2.0.8\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.6.0\n",
            "    Uninstalling zipp-3.6.0:\n",
            "      Successfully uninstalled zipp-3.6.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.0.1\n",
            "    Uninstalling typing-extensions-4.0.1:\n",
            "      Successfully uninstalled typing-extensions-4.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 59.4.0\n",
            "    Uninstalling setuptools-59.4.0:\n",
            "      Successfully uninstalled setuptools-59.4.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.26.0\n",
            "    Uninstalling requests-2.26.0:\n",
            "      Successfully uninstalled requests-2.26.0\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1-modules 0.2.8\n",
            "    Uninstalling pyasn1-modules-0.2.8:\n",
            "      Successfully uninstalled pyasn1-modules-0.2.8\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.1.1\n",
            "    Uninstalling oauthlib-3.1.1:\n",
            "      Successfully uninstalled oauthlib-3.1.1\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.4\n",
            "    Uninstalling cachetools-4.2.4:\n",
            "      Successfully uninstalled cachetools-4.2.4\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 1.3.0\n",
            "    Uninstalling requests-oauthlib-1.3.0:\n",
            "      Successfully uninstalled requests-oauthlib-1.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.2\n",
            "    Uninstalling importlib-metadata-4.8.2:\n",
            "      Successfully uninstalled importlib-metadata-4.8.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: cached-property\n",
            "    Found existing installation: cached-property 1.5.2\n",
            "    Uninstalling cached-property-1.5.2:\n",
            "      Successfully uninstalled cached-property-1.5.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.0\n",
            "    Uninstalling wheel-0.37.0:\n",
            "      Successfully uninstalled wheel-0.37.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 2.0.2\n",
            "    Uninstalling Werkzeug-2.0.2:\n",
            "      Successfully uninstalled Werkzeug-2.0.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.1\n",
            "    Uninstalling protobuf-3.19.1:\n",
            "      Successfully uninstalled protobuf-3.19.1\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.3.6\n",
            "    Uninstalling Markdown-3.3.6:\n",
            "      Successfully uninstalled Markdown-3.3.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.6.0\n",
            "    Uninstalling h5py-3.6.0:\n",
            "      Successfully uninstalled h5py-3.6.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 1.1.0\n",
            "    Uninstalling termcolor-1.1.0:\n",
            "      Successfully uninstalled termcolor-1.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Attempting uninstall: keras-preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Attempting uninstall: keras-applications\n",
            "    Found existing installation: Keras-Applications 1.0.8\n",
            "    Uninstalling Keras-Applications-1.0.8:\n",
            "      Successfully uninstalled Keras-Applications-1.0.8\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Attempting uninstall: astor\n",
            "    Found existing installation: astor 0.8.1\n",
            "    Uninstalling astor-0.8.1:\n",
            "      Successfully uninstalled astor-0.8.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow-metadata 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 1.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.0.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-1.0.0 astor-0.8.1 cached-property-1.5.2 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.8 gast-0.2.2 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.42.0 h5py-3.6.0 idna-3.3 importlib-metadata-4.8.2 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.6 numpy-1.21.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.8 scipy-1.4.1 setuptools-59.4.0 six-1.16.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 typing-extensions-4.0.1 urllib3-1.26.7 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.13.3 zipp-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "astor",
                  "google",
                  "numpy",
                  "pkg_resources",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "StZbGJVYdH8z",
        "outputId": "a6e48c7e-bf51-4260-c966-6fe09fb247cd"
      },
      "source": [
        "#we also need to downgrade h5py to prevent this: https://github.com/tensorflow/tensorflow/issues/44467\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "\n",
        "#restart runtime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Collecting six\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Using cached numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.6.0\n",
            "    Uninstalling h5py-3.6.0:\n",
            "      Successfully uninstalled h5py-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.4 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gXZWwuMdS4D",
        "outputId": "2d38e2c3-fe7c-446c-85b4-03fb89ade6db"
      },
      "source": [
        "!pip install matchzoo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matchzoo in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (1.21.4)\n",
            "Requirement already satisfied: tqdm>=4.19.4 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (4.62.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (2.6.3)\n",
            "Requirement already satisfied: dill>=0.2.7.1 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (0.3.4)\n",
            "Requirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (1.1.5)\n",
            "Requirement already satisfied: nltk>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (3.2.5)\n",
            "Requirement already satisfied: keras>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (2.3.1)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from matchzoo) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py>=2.8.0->matchzoo) (1.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->matchzoo) (3.12.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->matchzoo) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->matchzoo) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras>=2.3.0->matchzoo) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras>=2.3.0->matchzoo) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.3.0->matchzoo) (6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.1->matchzoo) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.1->matchzoo) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd0k37wbd-yG",
        "outputId": "52a553b8-dc6a-40d8-e0f7-6c184dd2a80f"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matchzoo as mz\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE9A9aEVfC22",
        "outputId": "9fb2b902-6872-4d5f-812a-4c94d808daa3"
      },
      "source": [
        "# import matchzoo \n",
        "print('data loading ...')\n",
        "train_pack_raw = mz.datasets.wiki_qa.load_data('train', task='ranking')\n",
        "dev_pack_raw = mz.datasets.wiki_qa.load_data('dev', task='ranking', filtered=True)\n",
        "test_pack_raw = mz.datasets.wiki_qa.load_data('test', task='ranking', filtered=True)\n",
        "print('data loaded as `train_pack_raw` `dev_pack_raw` `test_pack_raw`')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loading ...\n",
            "Downloading data from https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\n",
            "7094272/7094233 [==============================] - 0s 0us/step\n",
            "data loaded as `train_pack_raw` `dev_pack_raw` `test_pack_raw`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDTYZCYLd91v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKdKrDlXfC5X",
        "outputId": "98ac2850-b86a-4254-d930-aaa7f0f4529a"
      },
      "source": [
        "ranking_task = mz.tasks.Ranking(loss=mz.losses.RankHingeLoss())\n",
        "# ranking_task = mz.tasks.Ranking(loss=mz.losses.RankCrossEntropyLoss(num_neg=10))\n",
        "ranking_task.metrics = [\n",
        "    mz.metrics.NormalizedDiscountedCumulativeGain(k=3),\n",
        "    mz.metrics.NormalizedDiscountedCumulativeGain(k=5),\n",
        "    mz.metrics.MeanAveragePrecision(),\n",
        "    mz.metrics.AveragePrecision(),\n",
        "    mz.metrics.MeanReciprocalRank(),\n",
        "    mz.metrics.Precision()\n",
        "]\n",
        "print(\"`ranking_task` initialized with metrics\", ranking_task.metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`ranking_task` initialized with metrics [normalized_discounted_cumulative_gain@3(0.0), normalized_discounted_cumulative_gain@5(0.0), mean_average_precision(0.0), average_precision(0.0), mean_reciprocal_rank(0.0), precision@1(0.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XWL-k5adG22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr_fhz1kfC70",
        "outputId": "b9891c51-334b-45e2-be75-17725c7c3592"
      },
      "source": [
        "print(\"loading embedding ...\")\n",
        "glove_embedding = mz.datasets.embeddings.load_glove_embedding(dimension=300)\n",
        "print(\"embedding loaded as `glove_embedding`\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading embedding ...\n",
            "Downloading data from http://nlp.stanford.edu/data/glove.6B.zip\n",
            "862183424/862182613 [==============================] - 161s 0us/step\n",
            "embedding loaded as `glove_embedding`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj-yMbmWfC-T",
        "outputId": "f9e4365a-9d21-45c3-e40d-a5640195c991"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "def append_params_to_readme(model):\n",
        "    import tabulate\n",
        "    \n",
        "    with open('README.rst', 'a+') as f:\n",
        "        subtitle = model.params['model_class'].__name__\n",
        "        line = '#' * len(subtitle)\n",
        "        subtitle = subtitle + '\\n' + line + '\\n\\n'\n",
        "        f.write(subtitle)\n",
        "        \n",
        "        df = model.params.to_frame()[['Name', 'Value']]\n",
        "        table = tabulate.tabulate(df, tablefmt='rst', headers='keys') + '\\n\\n'\n",
        "        f.write(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1mZJ09hfDAo"
      },
      "source": [
        "preprocessor = mz.preprocessors.BasicPreprocessor(fixed_length_left=10, \n",
        "                                                  fixed_length_right=40, \n",
        "                                                  remove_stop_words=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Flcz1o0fDDZ",
        "outputId": "11101d58-a76e-4918-9715-99ead60da1ce"
      },
      "source": [
        "train_pack_processed = preprocessor.fit_transform(train_pack_raw)\n",
        "dev_pack_processed = preprocessor.transform(dev_pack_raw)\n",
        "test_pack_processed = preprocessor.transform(test_pack_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 2118/2118 [00:00<00:00, 7170.75it/s]\n",
            "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 18841/18841 [00:05<00:00, 3496.58it/s]\n",
            "Processing text_right with append: 100%|██████████| 18841/18841 [00:00<00:00, 749171.73it/s]\n",
            "Building FrequencyFilter from a datapack.: 100%|██████████| 18841/18841 [00:00<00:00, 182629.50it/s]\n",
            "Processing text_right with transform: 100%|██████████| 18841/18841 [00:00<00:00, 169579.47it/s]\n",
            "Processing text_left with extend: 100%|██████████| 2118/2118 [00:00<00:00, 577452.93it/s]\n",
            "Processing text_right with extend: 100%|██████████| 18841/18841 [00:00<00:00, 589808.35it/s]\n",
            "Building Vocabulary from a datapack.: 100%|██████████| 300980/300980 [00:00<00:00, 2666208.26it/s]\n",
            "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 2118/2118 [00:00<00:00, 7094.05it/s]\n",
            "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 18841/18841 [00:05<00:00, 3653.07it/s]\n",
            "Processing text_right with transform: 100%|██████████| 18841/18841 [00:00<00:00, 144674.60it/s]\n",
            "Processing text_left with transform: 100%|██████████| 2118/2118 [00:00<00:00, 222756.67it/s]\n",
            "Processing text_right with transform: 100%|██████████| 18841/18841 [00:00<00:00, 68157.27it/s] \n",
            "Processing length_left with len: 100%|██████████| 2118/2118 [00:00<00:00, 582679.78it/s]\n",
            "Processing length_right with len: 100%|██████████| 18841/18841 [00:00<00:00, 605424.75it/s]\n",
            "Processing text_left with transform: 100%|██████████| 2118/2118 [00:00<00:00, 91006.78it/s]\n",
            "Processing text_right with transform: 100%|██████████| 18841/18841 [00:00<00:00, 97973.31it/s]\n",
            "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 122/122 [00:00<00:00, 6174.35it/s]\n",
            "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 1115/1115 [00:00<00:00, 3484.31it/s]\n",
            "Processing text_right with transform: 100%|██████████| 1115/1115 [00:00<00:00, 95494.43it/s]\n",
            "Processing text_left with transform: 100%|██████████| 122/122 [00:00<00:00, 124140.00it/s]\n",
            "Processing text_right with transform: 100%|██████████| 1115/1115 [00:00<00:00, 129514.77it/s]\n",
            "Processing length_left with len: 100%|██████████| 122/122 [00:00<00:00, 152976.11it/s]\n",
            "Processing length_right with len: 100%|██████████| 1115/1115 [00:00<00:00, 318031.21it/s]\n",
            "Processing text_left with transform: 100%|██████████| 122/122 [00:00<00:00, 70366.49it/s]\n",
            "Processing text_right with transform: 100%|██████████| 1115/1115 [00:00<00:00, 99986.08it/s]\n",
            "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 237/237 [00:00<00:00, 7099.39it/s]\n",
            "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 2300/2300 [00:00<00:00, 3652.22it/s]\n",
            "Processing text_right with transform: 100%|██████████| 2300/2300 [00:00<00:00, 144149.23it/s]\n",
            "Processing text_left with transform: 100%|██████████| 237/237 [00:00<00:00, 144316.21it/s]\n",
            "Processing text_right with transform: 100%|██████████| 2300/2300 [00:00<00:00, 127692.32it/s]\n",
            "Processing length_left with len: 100%|██████████| 237/237 [00:00<00:00, 124708.32it/s]\n",
            "Processing length_right with len: 100%|██████████| 2300/2300 [00:00<00:00, 521764.25it/s]\n",
            "Processing text_left with transform: 100%|██████████| 237/237 [00:00<00:00, 82227.65it/s]\n",
            "Processing text_right with transform: 100%|██████████| 2300/2300 [00:00<00:00, 83962.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA8VwI_Sfej1",
        "outputId": "b6310703-f90a-41a8-ed57-f314ac9fcd03"
      },
      "source": [
        "model = mz.models.MatchPyramid()\n",
        "# load `input_shapes` and `embedding_input_dim` (vocab_size)\n",
        "model.params.update(preprocessor.context)\n",
        "model.params['task'] = ranking_task\n",
        "model.params['embedding_output_dim'] = 100\n",
        "model.params['embedding_trainable'] = True\n",
        "model.params['num_blocks'] = 2\n",
        "model.params['kernel_count'] = [16, 32]\n",
        "model.params['kernel_size'] = [[3, 3], [3, 3]]\n",
        "model.params['dpool_size'] = [3, 10]\n",
        "model.params['optimizer'] = 'adam'\n",
        "model.params['dropout_rate'] = 0.1\n",
        "model.build()\n",
        "model.compile()\n",
        "print(model.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_class                   <class 'matchzoo.models.match_pyramid.MatchPyramid'>\n",
            "input_shapes                  [(10,), (40,)]\n",
            "task                          Ranking Task\n",
            "optimizer                     adam\n",
            "with_embedding                True\n",
            "embedding_input_dim           17353\n",
            "embedding_output_dim          100\n",
            "embedding_trainable           True\n",
            "num_blocks                    2\n",
            "kernel_count                  [16, 32]\n",
            "kernel_size                   [[3, 3], [3, 3]]\n",
            "activation                    relu\n",
            "dpool_size                    [3, 10]\n",
            "padding                       same\n",
            "dropout_rate                  0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXLJKa-DgQzh",
        "outputId": "71298ecf-c842-40c8-eae2-1e4c241c8ec4"
      },
      "source": [
        "model.backend.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_left (InputLayer)          (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text_right (InputLayer)         (None, 40)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           multiple             1735300     text_left[0][0]                  \n",
            "                                                                 text_right[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "matching_layer_1 (MatchingLayer (None, 10, 40, 1)    0           embedding[0][0]                  \n",
            "                                                                 embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 10, 40, 16)   160         matching_layer_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 10, 40, 32)   4640        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dpool_index (InputLayer)        (None, 10, 40, 2)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dynamic_pooling_layer_1 (Dynami (None, 3, 10, 32)    0           conv2d_2[0][0]                   \n",
            "                                                                 dpool_index[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 960)          0           dynamic_pooling_layer_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 960)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            961         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,741,061\n",
            "Trainable params: 1,741,061\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_K67eMGgTI0"
      },
      "source": [
        "# embedding_matrix = glove_embedding.build_matrix(preprocessor.context['vocab_unit'].state['term_index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGdDOzz5gXjK"
      },
      "source": [
        "# model.load_embedding_matrix(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqarutz2gZ1q",
        "outputId": "7b08f198-2a9b-4dca-be26-0c682ce9b429"
      },
      "source": [
        "dpool_callback = mz.data_generator.callbacks.DynamicPooling(\n",
        "    fixed_length_left=10, \n",
        "    fixed_length_right=40\n",
        ")\n",
        "train_generator = mz.DataGenerator(\n",
        "    train_pack_processed,\n",
        "    mode='pair',\n",
        "    num_dup=2,\n",
        "    num_neg=1,\n",
        "    batch_size=20,\n",
        "    callbacks=[dpool_callback]\n",
        ")\n",
        "print('num batches:', len(train_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num batches: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od-s8sAFgbgD",
        "outputId": "1b6efb79-6ca9-4ee2-c99e-e650130d373a"
      },
      "source": [
        "test_generator = mz.DataGenerator(\n",
        "    test_pack_processed,\n",
        "    batch_size=20,\n",
        "    callbacks=[dpool_callback]\n",
        ")\n",
        "len(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUi1LrBTiEtD"
      },
      "source": [
        "test_x, test_y = test_generator[:]\n",
        "evaluate = mz.callbacks.EvaluateAllMetrics(model, x=test_x, y=test_y, batch_size=len(test_y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP2mcLZ1iIYY",
        "outputId": "53b732ea-7837-4cfd-9d39-1dc2b16f850e"
      },
      "source": [
        "%%time\n",
        "# history = model.fit_generator(train_generator, epochs=10, callbacks=[evaluate], workers=30, use_multiprocessing=True)\n",
        "history = model.fit_generator(train_generator, epochs=20, callbacks=[evaluate], workers=30, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 9.8574e-04\n",
            "Epoch 1/20\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5846056180815439 - normalized_discounted_cumulative_gain@5(0.0): 0.647604951823806 - mean_average_precision(0.0): 0.6036393494399267 - average_precision(0.0): 0.28028568253288505 - mean_reciprocal_rank(0.0): 0.6103287964574882 - precision@1(0.0): 0.4430379746835443\n",
            "Epoch 2/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0022\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.59739929949724 - normalized_discounted_cumulative_gain@5(0.0): 0.6519146750977272 - mean_average_precision(0.0): 0.604169243011322 - average_precision(0.0): 0.27732765524300657 - mean_reciprocal_rank(0.0): 0.6122625497153589 - precision@1(0.0): 0.43037974683544306\n",
            "Epoch 3/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 1.8980e-04\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5935242865379189 - normalized_discounted_cumulative_gain@5(0.0): 0.6447439196439303 - mean_average_precision(0.0): 0.6046124430587716 - average_precision(0.0): 0.2789363247098861 - mean_reciprocal_rank(0.0): 0.6118938293099961 - precision@1(0.0): 0.43037974683544306\n",
            "Epoch 4/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0046\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5807126519065305 - normalized_discounted_cumulative_gain@5(0.0): 0.641412281140858 - mean_average_precision(0.0): 0.5948565410430295 - average_precision(0.0): 0.27386528739180876 - mean_reciprocal_rank(0.0): 0.6020599690486433 - precision@1(0.0): 0.4177215189873418\n",
            "Epoch 5/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0022\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5807421479215985 - normalized_discounted_cumulative_gain@5(0.0): 0.6355819561291726 - mean_average_precision(0.0): 0.5890833502687856 - average_precision(0.0): 0.2724696554694608 - mean_reciprocal_rank(0.0): 0.5955024640151222 - precision@1(0.0): 0.4050632911392405\n",
            "Epoch 6/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 4.3395e-04\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5718395830313708 - normalized_discounted_cumulative_gain@5(0.0): 0.6312578497848479 - mean_average_precision(0.0): 0.5850675290061288 - average_precision(0.0): 0.26981736034248094 - mean_reciprocal_rank(0.0): 0.5931829305247026 - precision@1(0.0): 0.4050632911392405\n",
            "Epoch 7/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0000e+00\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5718395830313708 - normalized_discounted_cumulative_gain@5(0.0): 0.6312578497848479 - mean_average_precision(0.0): 0.5850675290061288 - average_precision(0.0): 0.26981736034248094 - mean_reciprocal_rank(0.0): 0.5931829305247026 - precision@1(0.0): 0.4050632911392405\n",
            "Epoch 8/20\n",
            "102/102 [==============================] - 2s 20ms/step - loss: 0.0051\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5895924561241982 - normalized_discounted_cumulative_gain@5(0.0): 0.6452495048225394 - mean_average_precision(0.0): 0.6057415942625636 - average_precision(0.0): 0.27925756014416725 - mean_reciprocal_rank(0.0): 0.6114371325211154 - precision@1(0.0): 0.4388185654008439\n",
            "Epoch 9/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0013\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5858618414932437 - normalized_discounted_cumulative_gain@5(0.0): 0.6449817378127404 - mean_average_precision(0.0): 0.6025630167637457 - average_precision(0.0): 0.27677617399776927 - mean_reciprocal_rank(0.0): 0.6089548662283505 - precision@1(0.0): 0.43037974683544306\n",
            "Epoch 10/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 2.4389e-04\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.585263859388576 - normalized_discounted_cumulative_gain@5(0.0): 0.641210889369912 - mean_average_precision(0.0): 0.5968867381338793 - average_precision(0.0): 0.27450516264194774 - mean_reciprocal_rank(0.0): 0.6015994161377631 - precision@1(0.0): 0.4219409282700422\n",
            "Epoch 11/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0018\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5756123905703747 - normalized_discounted_cumulative_gain@5(0.0): 0.641964303384486 - mean_average_precision(0.0): 0.5959340810876306 - average_precision(0.0): 0.2729876995290074 - mean_reciprocal_rank(0.0): 0.6014828648503256 - precision@1(0.0): 0.4219409282700422\n",
            "Epoch 12/20\n",
            "102/102 [==============================] - 2s 20ms/step - loss: 0.0019\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5718600705915186 - normalized_discounted_cumulative_gain@5(0.0): 0.640782415241969 - mean_average_precision(0.0): 0.5951753127517894 - average_precision(0.0): 0.2740429906918353 - mean_reciprocal_rank(0.0): 0.6024965599332688 - precision@1(0.0): 0.4219409282700422\n",
            "Epoch 13/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0039\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5361426211483794 - normalized_discounted_cumulative_gain@5(0.0): 0.6033324866849702 - mean_average_precision(0.0): 0.5608904064758495 - average_precision(0.0): 0.2608103675474673 - mean_reciprocal_rank(0.0): 0.5704810309240689 - precision@1(0.0): 0.38396624472573837\n",
            "Epoch 14/20\n",
            "102/102 [==============================] - 2s 22ms/step - loss: 0.0028\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5560894510871823 - normalized_discounted_cumulative_gain@5(0.0): 0.6233568093884837 - mean_average_precision(0.0): 0.5863119026300926 - average_precision(0.0): 0.268830759681611 - mean_reciprocal_rank(0.0): 0.593584981341183 - precision@1(0.0): 0.42616033755274263\n",
            "Epoch 15/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0075\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5518358862536948 - normalized_discounted_cumulative_gain@5(0.0): 0.6192684872189371 - mean_average_precision(0.0): 0.573902221283828 - average_precision(0.0): 0.26226129151288796 - mean_reciprocal_rank(0.0): 0.5782394642682227 - precision@1(0.0): 0.39662447257383965\n",
            "Epoch 16/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0019\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5563634256596715 - normalized_discounted_cumulative_gain@5(0.0): 0.6180893394259893 - mean_average_precision(0.0): 0.5778366760764757 - average_precision(0.0): 0.2666000880888776 - mean_reciprocal_rank(0.0): 0.5853590481961424 - precision@1(0.0): 0.4092827004219409\n",
            "Epoch 17/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.0012\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5613206052241616 - normalized_discounted_cumulative_gain@5(0.0): 0.6177733347864168 - mean_average_precision(0.0): 0.5851903722156887 - average_precision(0.0): 0.2688054279183703 - mean_reciprocal_rank(0.0): 0.5910505223796362 - precision@1(0.0): 0.4177215189873418\n",
            "Epoch 18/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 5.9898e-05\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5530101944996026 - normalized_discounted_cumulative_gain@5(0.0): 0.6138997316984849 - mean_average_precision(0.0): 0.5782643032165246 - average_precision(0.0): 0.2674906141862493 - mean_reciprocal_rank(0.0): 0.5842281407496099 - precision@1(0.0): 0.41350210970464135\n",
            "Epoch 19/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 5.9646e-04\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5592539515098962 - normalized_discounted_cumulative_gain@5(0.0): 0.6367785972400264 - mean_average_precision(0.0): 0.5939339281298808 - average_precision(0.0): 0.27186687200730825 - mean_reciprocal_rank(0.0): 0.6010260484944029 - precision@1(0.0): 0.4388185654008439\n",
            "Epoch 20/20\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 1.5010e-04\n",
            "Validation: normalized_discounted_cumulative_gain@3(0.0): 0.5602919624788486 - normalized_discounted_cumulative_gain@5(0.0): 0.6224486049210147 - mean_average_precision(0.0): 0.5835844791486697 - average_precision(0.0): 0.26832859610671567 - mean_reciprocal_rank(0.0): 0.5893186942764999 - precision@1(0.0): 0.4050632911392405\n",
            "CPU times: user 2min 27s, sys: 41.1 s, total: 3min 8s\n",
            "Wall time: 2min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpqxzHPZiKOr"
      },
      "source": [
        "# model.evaluate(test_x, test_y, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LvppWgihBF",
        "outputId": "0a229e37-545a-475b-fa43-01b360b65561"
      },
      "source": [
        "%%time\n",
        "model.evaluate(test_x, test_y, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.65 s, sys: 366 ms, total: 2.02 s\n",
            "Wall time: 1.29 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{average_precision(0.0): 0.26832859610671567,\n",
              " mean_average_precision(0.0): 0.5835844791486697,\n",
              " mean_reciprocal_rank(0.0): 0.5893186942764999,\n",
              " normalized_discounted_cumulative_gain@3(0.0): 0.5602919624788486,\n",
              " normalized_discounted_cumulative_gain@5(0.0): 0.6224486049210147,\n",
              " precision@1(0.0): 0.4050632911392405}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn33NPPujffc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}